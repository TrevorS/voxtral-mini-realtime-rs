# Project Status

## Overview

Pure Rust implementation of Voxtral Mini 4B Realtime using the Burn ML framework. Target: streaming ASR with WASM/browser support.

## Model Summary (Verified)

| Component | Layers | Dim | Heads | Window | Special |
|-----------|--------|-----|-------|--------|---------|
| Audio Encoder | 32 | 1280 | 32 MHA | 750 | Causal, ADA RMSNorm, biases |
| Language Model | 26 | 3072 | 32Q/8KV | 8192 | GQA 4:1, no biases, tied embed |
| Adapter | 2 | 5120â†’3072 | - | - | GELU activation |

**Timing:** 1 text token = 80ms audio = 1280 samples @ 16kHz (12.5 Hz frame rate)

## Implementation Status

### Phase 1: Foundation âœ…

| Component | Status | Notes |
|-----------|--------|-------|
| Project setup | âœ… Complete | Cargo.toml with Burn, features for CPU/WGPU/CUDA |
| Config parsing | âœ… Complete | Parses nested `params.json`, verified against model |
| Mel spectrogram | âœ… Complete | Pure Rust FFT, 16kHz/128 bins/hop=160/win=400 |
| Audio I/O | âœ… Complete | WAV load/save with format conversion |
| Resampling | âœ… Complete | High-quality FFT resampling to 16kHz |
| Tokenizer wrapper | âœ… Complete | Tekken tokenizer integration |
| Model download | âœ… Complete | `scripts/download_model.py` |

**Test counts:** 67 unit tests passing, clippy clean
**Model downloaded:** 8.86 GB weights + config + tokenizer

### Development Tools âœ…

| Script | Purpose |
|--------|---------|
| `scripts/inspect_weights.py` | Browse SafeTensors: component summaries, shapes, stats |
| `scripts/dump_weight_names.py` | Get full weight paths (not truncated) |
| `scripts/reference_forward.py` | Generate reference outputs for RMSNorm, RoPE, SwiGLU, Conv, Attention |
| `scripts/compare_tensors.py` | Compare Rust outputs vs Python reference with tolerances |

**Test data generated:** `test_data/*.npy` - reference inputs/outputs for all core components
**Rust test utilities:** `src/test_utils.rs` - load_npy, assert_tensors_close

### Phase 2: Audio Encoder âœ…

| Component | Status | Notes |
|-----------|--------|-------|
| Conv1d downsampler | âœ… Complete | 128â†’1280â†’1280, stride=2, 4x downsample, GELU |
| RMSNorm | âœ… Complete | Validated against reference (max_diff < 1e-3) |
| ADA RMSNorm | âœ… Complete | T-conditional, validated against reference |
| RoPE embeddings | âœ… Complete | theta=1M, interleaved layout, validated |
| SwiGLU MLP | âœ… Complete | gate/up/down, validated against reference |
| Causal self-attention | âœ… Complete | MHA + GQA support, sliding window, validated |
| EncoderLayer | âœ… Complete | Full layer with ADA norm, attn, MLP, residuals |
| 32-layer stack | âœ… Complete | Full AudioEncoder with configurable layers |

### Phase 3: Language Model âœ…

| Component | Status | Notes |
|-----------|--------|-------|
| Token embeddings | âœ… Complete | vocab=131072, dim=3072 |
| GQA attention | âœ… Complete | 32Q/8KV heads, head_dim=128 |
| Sliding window | âœ… Complete | 8192 tokens |
| SwiGLU MLP | âœ… Complete | hidden=9216, no biases |
| DecoderLayer | âœ… Complete | Full layer with ADA norm, GQA, MLP |
| 26-layer stack | âœ… Complete | LanguageModel with configurable layers |
| LM head | âœ… Complete | Tied with embeddings |

### Phase 4: Integration ðŸ”„

| Component | Status | Notes |
|-----------|--------|-------|
| AudioLanguageAdapter | âœ… Complete | Linear(5120)â†’GELUâ†’Linear(3072) |
| VoxtralModel | âœ… Complete | Full end-to-end model combining all components |
| Weight loading infra | âœ… Complete | SafeTensors â†’ Burn tensors, supports F32/F16/BF16 |
| KV cache | âœ… Complete | Concatenation-based, sliding window eviction |
| Layer cache integration | âœ… Complete | forward_with_cache on all layers |
| E2E forward pass | âœ… Complete | test_e2e.rs verified with random weights |
| Full weight loading | âœ… Complete | VoxtralModelLoader loads 8GB SafeTensors into model |
| Streaming loop | ðŸ”² Pending | Incremental mel + causal forward |

### Phase 5: Browser/WASM ðŸ”²

| Component | Status | Notes |
|-----------|--------|-------|
| WGPU backend | ðŸ”² Pending | Test with CPU fallback |
| Web Audio API | ðŸ”² Pending | Microphone input |
| WebWorker | ðŸ”² Pending | Off-main-thread inference |
| Quantization | ðŸ”² Pending | INT8/INT4 for model size |

## Project Structure

```
voxtral-mini-realtime-rs/
â”œâ”€â”€ Cargo.toml              # Burn framework, CPU/WGPU/CUDA features
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_model.py   # HuggingFace model download
â”‚   â”œâ”€â”€ inspect_weights.py  # SafeTensors browser
â”‚   â”œâ”€â”€ dump_weight_names.py # Full weight paths
â”‚   â”œâ”€â”€ reference_forward.py # Generate test data
â”‚   â””â”€â”€ compare_tensors.py  # Validate Rust vs Python
â”œâ”€â”€ test_data/              # Reference tensors (gitignored)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ voxtral/            # Downloaded model (gitignored)
â”‚       â”œâ”€â”€ consolidated.safetensors  # 8.86 GB
â”‚       â”œâ”€â”€ params.json               # Architecture config
â”‚       â””â”€â”€ tekken.json               # Tokenizer
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs              # Public API (VoxtralRealtime<B>)
â”‚   â”œâ”€â”€ main.rs             # Simple placeholder
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ config.rs       # VoxtralConfig parser (verified)
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ io.rs           # AudioBuffer, WAV I/O
â”‚   â”‚   â”œâ”€â”€ mel.rs          # MelSpectrogram extractor
â”‚   â”‚   â””â”€â”€ resample.rs     # FFT-based resampling
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â”‚   â””â”€â”€ mod.rs          # Tekken tokenizer wrapper
â”‚   â””â”€â”€ bin/
â”‚       â””â”€â”€ transcribe.rs   # CLI stub
â””â”€â”€ docs/
    â”œâ”€â”€ VOXTRAL_ARCHITECTURE.md  # Model deep dive (verified)
    â”œâ”€â”€ CONTINUATION.md          # This file
    â””â”€â”€ VALIDATION.md            # Validation strategy
```

## Getting Started

### Download Model Weights

```bash
# Download model files (~9GB total) - no auth required
./scripts/download_model.py

# Or specify custom output directory
./scripts/download_model.py --output-dir /path/to/models/voxtral
```

This downloads:
- `consolidated.safetensors` (8.86 GB) - Model weights in BF16
- `params.json` (1.34 KB) - Architecture configuration
- `tekken.json` (14.9 MB) - Tokenizer vocabulary

### Build & Test

```bash
# Build (CPU backend)
cargo build

# Run tests
cargo test

# Run with WGPU backend
cargo build --features wgpu --no-default-features

# Run with CUDA backend
cargo build --features cuda --no-default-features
```

## Dependencies

| Crate | Purpose |
|-------|---------|
| `burn` | ML framework with swappable backends |
| `tokenizers` | Tekken tokenizer |
| `hound` | WAV I/O |
| `rubato` | Audio resampling |
| `rustfft` | FFT for mel spectrograms |
| `safetensors` | Weight loading |
| `serde` | Configuration parsing |

## Key Discoveries from params.json

1. **Frame rate is 12.5 Hz** (not 100 Hz) after all downsampling
   - Raw mel: 100 Hz (16000/160)
   - After 4x conv downsample: 25 Hz
   - After 2x reshape: 12.5 Hz = 80ms per token

2. **ADA RMSNorm confirmed**
   - `ada_rms_norm_t_cond: true`
   - `ada_rms_norm_t_cond_dim: 32`
   - Used in audio encoder only

3. **Encoder has biases, LLM does not**
   - Encoder attention: `use_biases: true`
   - LLM attention: `use_biases: false`

4. **Config structure is nested**
   - LLM params at top level
   - Encoder at `multimodal.whisper_model_args.encoder_args`
   - Audio specs at `.encoder_args.audio_encoding_args`

## Key Discoveries from SafeTensors Weights

Weight structure (discovered via `inspect_weights.py`):

| Component | Tensors | Params | Prefix |
|-----------|---------|--------|--------|
| Audio Encoder | 421 | 970M | `mm_streams_embeddings.embedding_module.whisper_encoder.*` |
| LLM Decoder | 286 | 3.03B | `layers.{N}.*` |
| Token Embeddings | 1 | 403M | `mm_streams_embeddings.embedding_module.tok_embeddings.weight` |
| Adapter | 2 | 25M | `mm_streams_embeddings.embedding_module.audio_language_projection.*` |
| Final Norm | 1 | 3K | `norm.weight` |

Key weight patterns:
```
# LLM layer structure (26 layers)
layers.{N}.ada_rms_norm_t_cond.0.weight    # [32, 3072] - ADA RMSNorm in LLM!
layers.{N}.ada_rms_norm_t_cond.2.weight    # [3072, 32]
layers.{N}.attention_norm.weight           # [3072]
layers.{N}.attention.wq/wk/wv/wo.weight   # GQA attention
layers.{N}.ffn_norm.weight                 # [3072]
layers.{N}.feed_forward.w1/w2/w3.weight   # SwiGLU MLP

# Encoder layer structure (32 layers)
mm_streams_embeddings.embedding_module.whisper_encoder.transformer.layers.{N}.*
  .attention.wq/wk/wv.weight + .wq/wv.bias    # MHA with biases
  .attention.wo.weight + .wo.bias
  .feed_forward.w1/w2/w3.weight + .w2.bias

# Conv downsampler
mm_streams_embeddings.embedding_module.whisper_encoder.conv_layers.0.conv.*  # [1280, 128, 3]
mm_streams_embeddings.embedding_module.whisper_encoder.conv_layers.1.conv.*  # [1280, 1280, 3]

# Adapter (Sequential with indices 0, 2 - GELU at index 1)
mm_streams_embeddings.embedding_module.audio_language_projection.0.weight  # [3072, 5120]
mm_streams_embeddings.embedding_module.audio_language_projection.2.weight  # [3072, 3072]
```

**Correction:** ADA RMSNorm is ONLY in decoder (LLM) layers, NOT in encoder layers.
The encoder uses standard RMSNorm. This contradicts an earlier note in this document.

## Next Steps

1. ~~Download model weights~~ âœ…
2. ~~Verify config parsing~~ âœ…
3. Inspect SafeTensors weight names
4. Implement shared components (RMSNorm, RoPE, SwiGLU)
5. Build audio encoder layer by layer
6. Validate against Python reference
7. Implement LLM decoder
8. Wire up streaming pipeline
9. Test WGPU backend

## Open Questions

1. **ADA RMSNorm t_embed**: How is the temporal conditioning vector computed?
   - No learned t_embed weights in the model - it must be computed or passed in
   - Zeros works for inference but may not be optimal
   - Need to find reference implementation to understand proper values

2. **Tekken tokenizer**: âœ… Resolved
   - Custom loader implemented - HuggingFace `tokenizers` crate doesn't support Tekken format
   - Tekken uses base64-encoded token bytes with some null token_str entries

3. **Weight names**: âœ… Resolved
   - Encoder: `mm_streams_embeddings.embedding_module.whisper_encoder.*`
   - Decoder: `layers.{N}.*`

4. **WASM size**: 8.86GB model needs quantization for browser
   - INT8: ~2.2GB, INT4: ~1.1GB
   - May need dynamic quantization or progressive loading

5. **Model outputs all spaces**: Forward pass runs but outputs token 32 (space) for all positions
   - Mel spectrogram normalization has been verified against Python reference
   - Issue likely in decoder processing or t_embed handling
   - Need reference Python inference to compare intermediate outputs

## Known Issues

### Mel Spectrogram Differences
- Our Rust mel computation differs slightly from torchaudio's MelSpectrogram
- Python reference mel (generated via `scripts/reference_inference.py`) can be loaded for testing
- Root cause: filterbank normalization differences between librosa-style (Rust) and torchaudio

## Reference Materials

- [Voxtral Model Card](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602)
- [Burn Documentation](https://burn.dev/)
- qwen3-tts-rs patterns (../qwen3-tts-rs)
