<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voxtral Mini 4B Realtime - Browser Demo</title>
    <style>
        :root {
            --bg: #1a1a2e;
            --surface: #16213e;
            --primary: #e94560;
            --primary-hover: #ff6b6b;
            --success: #5cb85c;
            --text: #eaeaea;
            --text-muted: #888;
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            margin: 0;
            padding: 2rem;
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        h1 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }

        .subtitle {
            color: var(--text-muted);
            margin-bottom: 2rem;
        }

        .card {
            background: var(--surface);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .card h2 {
            margin-top: 0;
            font-size: 1.1rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #666;
        }

        .status-dot.loading { background: #f0ad4e; }
        .status-dot.ready { background: #5cb85c; }
        .status-dot.error { background: #d9534f; }
        .status-dot.recording { background: #d9534f; animation: pulse 1s infinite; }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        button {
            background: var(--primary);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background 0.2s;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
        }

        button:hover:not(:disabled) {
            background: var(--primary-hover);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        button.recording {
            background: #d9534f;
            animation: pulse 1s infinite;
        }

        button.secondary {
            background: #444;
        }

        button.secondary:hover:not(:disabled) {
            background: #555;
        }

        .file-input {
            margin-bottom: 1rem;
        }

        .file-input input {
            display: none;
        }

        .file-input label {
            display: inline-block;
            padding: 0.75rem 1.5rem;
            background: var(--surface);
            border: 2px dashed #444;
            border-radius: 8px;
            cursor: pointer;
            transition: border-color 0.2s;
        }

        .file-input label:hover {
            border-color: var(--primary);
        }

        .file-input label.loaded {
            border-color: var(--success);
            border-style: solid;
        }

        .transcription {
            background: #0d1117;
            border-radius: 8px;
            padding: 1rem;
            min-height: 100px;
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }

        .transcription.empty {
            color: var(--text-muted);
            font-style: italic;
        }

        .progress {
            height: 4px;
            background: #333;
            border-radius: 2px;
            overflow: hidden;
            margin-bottom: 1rem;
        }

        .progress-bar {
            height: 100%;
            background: var(--primary);
            width: 0%;
            transition: width 0.3s;
        }

        .info {
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .info code {
            background: #333;
            padding: 0.1rem 0.3rem;
            border-radius: 4px;
        }

        .input-row {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            margin-bottom: 1rem;
        }

        .input-group {
            flex: 1;
            min-width: 200px;
        }

        .input-group label {
            display: block;
            margin-bottom: 0.5rem;
            color: var(--text-muted);
            font-size: 0.9rem;
        }

        .mic-visualizer {
            height: 40px;
            background: #0d1117;
            border-radius: 4px;
            margin-bottom: 1rem;
            display: none;
            align-items: center;
            justify-content: center;
        }

        .mic-visualizer.active {
            display: flex;
        }

        .mic-visualizer .bars {
            display: flex;
            gap: 3px;
            height: 30px;
            align-items: flex-end;
        }

        .mic-visualizer .bar {
            width: 4px;
            background: var(--primary);
            border-radius: 2px;
            animation: bar-bounce 0.5s ease-in-out infinite;
        }

        @keyframes bar-bounce {
            0%, 100% { height: 10%; }
            50% { height: 100%; }
        }

        .mic-visualizer .bar:nth-child(1) { animation-delay: 0s; }
        .mic-visualizer .bar:nth-child(2) { animation-delay: 0.1s; }
        .mic-visualizer .bar:nth-child(3) { animation-delay: 0.2s; }
        .mic-visualizer .bar:nth-child(4) { animation-delay: 0.3s; }
        .mic-visualizer .bar:nth-child(5) { animation-delay: 0.4s; }

        .timer {
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 1.2rem;
            margin-left: 1rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voxtral Mini 4B Realtime</h1>
        <p class="subtitle">Streaming ASR in the browser powered by Rust + WASM</p>

        <div class="card">
            <h2>Model Status</h2>
            <div class="status">
                <div class="status-dot" id="status-dot"></div>
                <span id="status-text">Not loaded</span>
            </div>
            <div class="progress" id="progress-container" style="display: none;">
                <div class="progress-bar" id="progress-bar"></div>
            </div>
            <div style="display: flex; align-items: center; gap: 0.5rem; flex-wrap: wrap;">
                <button id="load-btn" disabled>Load Model from Server</button>
                <span id="cache-info" class="info"></span>
                <button id="clear-cache-btn" class="secondary" style="display: none;">Clear Cache</button>
            </div>
            <p class="info">
                Shards are cached in the browser after first fetch.
                Subsequent transcriptions load from cache instantly.
            </p>
        </div>

        <div class="card">
            <h2>Audio Input</h2>

            <div class="mic-visualizer" id="mic-visualizer">
                <div class="bars">
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                </div>
                <span class="timer" id="rec-timer">0:00</span>
            </div>

            <div style="margin-bottom: 1rem;">
                <button id="mic-btn" disabled>Start Microphone</button>
                <button id="stop-mic-btn" class="secondary" style="display: none;">Stop & Transcribe</button>
                <button id="cancel-mic-btn" class="secondary" style="display: none;">Cancel</button>
            </div>

            <div style="margin-bottom: 1rem; color: var(--text-muted);">— or —</div>

            <div class="file-input">
                <input type="file" id="audio-file" accept="audio/*">
                <label for="audio-file">Select audio file</label>
            </div>
            <p id="audio-info" class="info"></p>
            <button id="transcribe-btn" disabled>Transcribe File</button>
        </div>

        <div class="card">
            <h2>Transcription</h2>
            <div class="transcription empty" id="transcription">
                Transcription will appear here...
            </div>
        </div>
    </div>

    <script type="module">
        import { VoxtralClient } from './voxtral-client.js';

        const client = new VoxtralClient();

        // Server shard URLs
        const SHARDS_BASE = '/models/shards-safetensors';
        const TOKENIZER_URL = '/models/voxtral/tekken.json';
        const serverUrls = {
            tokenizer: TOKENIZER_URL,
            encoder: `${SHARDS_BASE}/encoder.safetensors.gz`,
            adapter: `${SHARDS_BASE}/adapter.safetensors.gz`,
            manifest: `${SHARDS_BASE}/manifest.json`,
            baseUrl: SHARDS_BASE,
        };

        // UI elements
        const statusDot = document.getElementById('status-dot');
        const statusText = document.getElementById('status-text');
        const progressContainer = document.getElementById('progress-container');
        const progressBar = document.getElementById('progress-bar');
        const transcriptionEl = document.getElementById('transcription');
        const audioInfo = document.getElementById('audio-info');
        const loadBtn = document.getElementById('load-btn');

        // Buttons
        const micBtn = document.getElementById('mic-btn');
        const stopMicBtn = document.getElementById('stop-mic-btn');
        const cancelMicBtn = document.getElementById('cancel-mic-btn');
        const transcribeBtn = document.getElementById('transcribe-btn');

        // Mic UI
        const micVisualizer = document.getElementById('mic-visualizer');
        const recTimer = document.getElementById('rec-timer');

        // Cache UI
        const cacheInfo = document.getElementById('cache-info');
        const clearCacheBtn = document.getElementById('clear-cache-btn');

        async function updateCacheInfo() {
            const count = await VoxtralClient.getCachedShardCount();
            if (count > 0) {
                cacheInfo.textContent = `(${count} shards cached)`;
                clearCacheBtn.style.display = '';
            } else {
                cacheInfo.textContent = '';
                clearCacheBtn.style.display = 'none';
            }
        }

        clearCacheBtn.addEventListener('click', async () => {
            await VoxtralClient.clearCache();
            updateCacheInfo();
        });

        // State
        let serverReady = false;
        let audioFile = null;
        let recStartTime = null;
        let recTimerInterval = null;

        function updateStatus(status, text) {
            statusDot.className = 'status-dot ' + status;
            statusText.textContent = text;
        }

        function updateButtons() {
            micBtn.disabled = !serverReady;
            transcribeBtn.disabled = !(serverReady && audioFile);
        }

        // Progress callback
        client.setProgressCallback((stage, percent) => {
            updateStatus('loading', stage);
            if (percent !== undefined) {
                progressContainer.style.display = 'block';
                progressBar.style.width = percent + '%';
            }
        });

        // Initialize WASM
        async function initClient() {
            try {
                updateStatus('loading', 'Initializing WASM + WebGPU...');
                await client.init();
                updateStatus('', 'WASM ready. Click "Load Model from Server".');
                loadBtn.disabled = false;
                updateCacheInfo();
            } catch (e) {
                updateStatus('error', 'Failed to initialize: ' + e.message);
                console.error(e);
            }
        }

        // Load model from server (validates shards exist)
        loadBtn.addEventListener('click', async () => {
            loadBtn.disabled = true;
            try {
                updateStatus('loading', 'Checking server for model shards...');

                const manifestResp = await fetch(serverUrls.manifest);
                if (!manifestResp.ok) throw new Error('Manifest not found on server');
                const manifest = await manifestResp.json();

                // Quick check that tokenizer is available
                const tokResp = await fetch(serverUrls.tokenizer, { method: 'HEAD' });
                if (!tokResp.ok) throw new Error('Tokenizer not found on server');

                serverReady = true;
                const sizeGB = (manifest.total_size / 1e9).toFixed(1);
                updateStatus('ready', `Model available (${manifest.shards.length} shards, ${sizeGB} GB). Select audio to transcribe.`);
                updateButtons();
            } catch (e) {
                updateStatus('error', 'Server error: ' + e.message);
                loadBtn.disabled = false;
                console.error(e);
            }
        });

        // Load audio file
        document.getElementById('audio-file').addEventListener('change', async (e) => {
            audioFile = e.target.files[0];
            if (!audioFile) return;
            audioInfo.textContent = `File: ${audioFile.name} (${(audioFile.size / 1024).toFixed(1)} KB)`;
            updateButtons();
        });

        // Transcribe file (phased pipeline)
        transcribeBtn.addEventListener('click', async () => {
            if (!serverReady || !audioFile) return;

            transcribeBtn.disabled = true;
            micBtn.disabled = true;
            progressContainer.style.display = 'block';
            transcriptionEl.textContent = 'Loading shards and transcribing...';
            transcriptionEl.classList.add('empty');

            try {
                const text = await client.transcribeFilePhased(audioFile, serverUrls);
                transcriptionEl.textContent = text || '(No speech detected)';
                transcriptionEl.classList.remove('empty');
                progressContainer.style.display = 'none';
                updateStatus('ready', 'Done! Select audio to transcribe again.');
                updateCacheInfo();
            } catch (e) {
                transcriptionEl.textContent = 'Error: ' + (e.message || String(e));
                updateStatus('error', 'Transcription failed');
                progressContainer.style.display = 'none';
                console.error(e);
            } finally {
                updateButtons();
            }
        });

        // Microphone recording
        function updateRecTimer() {
            if (!recStartTime) return;
            const elapsed = Math.floor((Date.now() - recStartTime) / 1000);
            const mins = Math.floor(elapsed / 60);
            const secs = elapsed % 60;
            recTimer.textContent = `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        micBtn.addEventListener('click', async () => {
            try {
                await client.startMicrophone();

                micBtn.style.display = 'none';
                stopMicBtn.style.display = '';
                cancelMicBtn.style.display = '';
                micVisualizer.classList.add('active');
                statusDot.classList.add('recording');

                recStartTime = Date.now();
                recTimerInterval = setInterval(updateRecTimer, 1000);
                updateRecTimer();
            } catch (e) {
                updateStatus('error', 'Microphone error: ' + e.message);
                console.error(e);
            }
        });

        stopMicBtn.addEventListener('click', async () => {
            clearInterval(recTimerInterval);
            recTimerInterval = null;

            micBtn.style.display = '';
            stopMicBtn.style.display = 'none';
            cancelMicBtn.style.display = 'none';
            micVisualizer.classList.remove('active');
            statusDot.classList.remove('recording');

            progressContainer.style.display = 'block';
            transcriptionEl.textContent = 'Loading shards and transcribing...';
            transcriptionEl.classList.add('empty');

            try {
                const text = await client.stopAndTranscribePhased(serverUrls);
                transcriptionEl.textContent = text || '(No speech detected)';
                transcriptionEl.classList.remove('empty');
                progressContainer.style.display = 'none';
                updateStatus('ready', 'Done!');
                updateCacheInfo();
            } catch (e) {
                transcriptionEl.textContent = 'Error: ' + (e.message || String(e));
                updateStatus('error', 'Transcription failed');
                progressContainer.style.display = 'none';
                console.error(e);
            } finally {
                updateButtons();
            }
        });

        cancelMicBtn.addEventListener('click', () => {
            client.cancelMicrophone();

            clearInterval(recTimerInterval);
            recTimerInterval = null;

            micBtn.style.display = '';
            stopMicBtn.style.display = 'none';
            cancelMicBtn.style.display = 'none';
            micVisualizer.classList.remove('active');
            statusDot.classList.remove('recording');
            updateStatus('ready', 'Model available. Select audio to transcribe.');
        });

        initClient();
    </script>
</body>
</html>
