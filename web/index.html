<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voxtral Mini 4B Realtime - Browser Demo</title>
    <style>
        :root {
            --bg: #1a1a2e;
            --surface: #16213e;
            --primary: #e94560;
            --primary-hover: #ff6b6b;
            --success: #5cb85c;
            --text: #eaeaea;
            --text-muted: #888;
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            margin: 0;
            padding: 2rem;
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        h1 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }

        .subtitle {
            color: var(--text-muted);
            margin-bottom: 2rem;
        }

        .card {
            background: var(--surface);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .card h2 {
            margin-top: 0;
            font-size: 1.1rem;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #666;
        }

        .status-dot.loading { background: #f0ad4e; }
        .status-dot.ready { background: #5cb85c; }
        .status-dot.error { background: #d9534f; }
        .status-dot.recording { background: #d9534f; animation: pulse 1s infinite; }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        button {
            background: var(--primary);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background 0.2s;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
        }

        button:hover:not(:disabled) {
            background: var(--primary-hover);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        button.recording {
            background: #d9534f;
            animation: pulse 1s infinite;
        }

        button.secondary {
            background: #444;
        }

        button.secondary:hover:not(:disabled) {
            background: #555;
        }

        .file-input {
            margin-bottom: 1rem;
        }

        .file-input input {
            display: none;
        }

        .file-input label {
            display: inline-block;
            padding: 0.75rem 1.5rem;
            background: var(--surface);
            border: 2px dashed #444;
            border-radius: 8px;
            cursor: pointer;
            transition: border-color 0.2s;
        }

        .file-input label:hover {
            border-color: var(--primary);
        }

        .file-input label.loaded {
            border-color: var(--success);
            border-style: solid;
        }

        .transcription {
            background: #0d1117;
            border-radius: 8px;
            padding: 1rem;
            min-height: 100px;
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }

        .transcription.empty {
            color: var(--text-muted);
            font-style: italic;
        }

        .progress {
            height: 4px;
            background: #333;
            border-radius: 2px;
            overflow: hidden;
            margin-bottom: 1rem;
        }

        .progress-bar {
            height: 100%;
            background: var(--primary);
            width: 0%;
            transition: width 0.3s;
        }

        .info {
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .info code {
            background: #333;
            padding: 0.1rem 0.3rem;
            border-radius: 4px;
        }

        .input-row {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            margin-bottom: 1rem;
        }

        .input-group {
            flex: 1;
            min-width: 200px;
        }

        .input-group label {
            display: block;
            margin-bottom: 0.5rem;
            color: var(--text-muted);
            font-size: 0.9rem;
        }

        .mic-visualizer {
            height: 40px;
            background: #0d1117;
            border-radius: 4px;
            margin-bottom: 1rem;
            display: none;
            align-items: center;
            justify-content: center;
        }

        .mic-visualizer.active {
            display: flex;
        }

        .mic-visualizer .bars {
            display: flex;
            gap: 3px;
            height: 30px;
            align-items: flex-end;
        }

        .mic-visualizer .bar {
            width: 4px;
            background: var(--primary);
            border-radius: 2px;
            animation: bar-bounce 0.5s ease-in-out infinite;
        }

        @keyframes bar-bounce {
            0%, 100% { height: 10%; }
            50% { height: 100%; }
        }

        .mic-visualizer .bar:nth-child(1) { animation-delay: 0s; }
        .mic-visualizer .bar:nth-child(2) { animation-delay: 0.1s; }
        .mic-visualizer .bar:nth-child(3) { animation-delay: 0.2s; }
        .mic-visualizer .bar:nth-child(4) { animation-delay: 0.3s; }
        .mic-visualizer .bar:nth-child(5) { animation-delay: 0.4s; }

        .timer {
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 1.2rem;
            margin-left: 1rem;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voxtral Mini 4B Realtime</h1>
        <p class="subtitle">Streaming ASR in the browser — Q4 GGUF + Rust + WASM + WebGPU</p>

        <div class="card">
            <h2>Model</h2>
            <div class="status">
                <div class="status-dot" id="status-dot"></div>
                <span id="status-text">Not loaded</span>
            </div>
            <div class="progress" id="progress-container" style="display: none;">
                <div class="progress-bar" id="progress-bar"></div>
            </div>

            <div class="input-row">
                <div class="input-group">
                    <label for="gguf-file">GGUF Model (~2 GB)</label>
                    <div class="file-input">
                        <input type="file" id="gguf-file" accept=".gguf">
                        <label for="gguf-file" id="gguf-label">Select .gguf file</label>
                    </div>
                </div>
                <div class="input-group">
                    <label for="tokenizer-file">Tokenizer JSON</label>
                    <div class="file-input">
                        <input type="file" id="tokenizer-file" accept=".json">
                        <label for="tokenizer-file" id="tokenizer-label">Select tekken.json</label>
                    </div>
                </div>
            </div>
            <button id="load-btn" disabled>Load from Files</button>
            <button id="load-server-btn" disabled>Load from Server</button>
            <p class="info">
                Pick local files or load pre-sharded model from the server.
            </p>
        </div>

        <div class="card">
            <h2>Audio Input</h2>

            <div class="mic-visualizer" id="mic-visualizer">
                <div class="bars">
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                    <div class="bar"></div>
                </div>
                <span class="timer" id="rec-timer">0:00</span>
            </div>

            <div style="margin-bottom: 1rem;">
                <button id="mic-btn" disabled>Start Microphone</button>
                <button id="stop-mic-btn" class="secondary" style="display: none;">Stop & Transcribe</button>
                <button id="cancel-mic-btn" class="secondary" style="display: none;">Cancel</button>
            </div>

            <div style="margin-bottom: 1rem; color: var(--text-muted);">— or —</div>

            <div class="file-input">
                <input type="file" id="audio-file" accept="audio/*">
                <label for="audio-file">Select audio file</label>
            </div>
            <p id="audio-info" class="info"></p>
            <button id="transcribe-btn" disabled>Transcribe File</button>
        </div>

        <div class="card">
            <h2>Transcription</h2>
            <div class="transcription empty" id="transcription">
                Transcription will appear here...
            </div>
        </div>
    </div>

    <script type="module">
        import { VoxtralClient } from './voxtral-client.js';

        const client = new VoxtralClient();

        // UI elements
        const statusDot = document.getElementById('status-dot');
        const statusText = document.getElementById('status-text');
        const progressContainer = document.getElementById('progress-container');
        const progressBar = document.getElementById('progress-bar');
        const transcriptionEl = document.getElementById('transcription');
        const audioInfo = document.getElementById('audio-info');
        const loadBtn = document.getElementById('load-btn');

        // Model file inputs
        const ggufInput = document.getElementById('gguf-file');
        const tokenizerInput = document.getElementById('tokenizer-file');
        const ggufLabel = document.getElementById('gguf-label');
        const tokenizerLabel = document.getElementById('tokenizer-label');

        // Buttons
        const micBtn = document.getElementById('mic-btn');
        const stopMicBtn = document.getElementById('stop-mic-btn');
        const cancelMicBtn = document.getElementById('cancel-mic-btn');
        const transcribeBtn = document.getElementById('transcribe-btn');

        // Mic UI
        const micVisualizer = document.getElementById('mic-visualizer');
        const recTimer = document.getElementById('rec-timer');

        // State
        let ggufFile = null;
        let tokenizerFile = null;
        let audioFile = null;
        let recStartTime = null;
        let recTimerInterval = null;

        function updateStatus(status, text) {
            statusDot.className = 'status-dot ' + status;
            statusText.textContent = text;
        }

        const loadServerBtn = document.getElementById('load-server-btn');

        function updateButtons() {
            loadBtn.disabled = !(client.ready && ggufFile && tokenizerFile && !client.modelLoaded);
            loadServerBtn.disabled = !(client.ready && !client.modelLoaded);
            micBtn.disabled = !client.isReady();
            transcribeBtn.disabled = !(client.isReady() && audioFile);
        }

        // Progress callback
        client.setProgressCallback((stage, percent) => {
            updateStatus('loading', stage);
            if (percent !== undefined) {
                progressContainer.style.display = 'block';
                progressBar.style.width = percent + '%';
            }
        });

        // Model file selection
        ggufInput.addEventListener('change', (e) => {
            ggufFile = e.target.files[0];
            if (ggufFile) {
                ggufLabel.textContent = ggufFile.name;
                ggufLabel.classList.add('loaded');
            }
            updateButtons();
        });

        tokenizerInput.addEventListener('change', (e) => {
            tokenizerFile = e.target.files[0];
            if (tokenizerFile) {
                tokenizerLabel.textContent = tokenizerFile.name;
                tokenizerLabel.classList.add('loaded');
            }
            updateButtons();
        });

        // Initialize WASM
        async function initClient() {
            try {
                updateStatus('loading', 'Initializing WASM + WebGPU...');
                await client.init();
                updateStatus('', 'WASM ready. Select model files to load.');
                updateButtons();
            } catch (e) {
                updateStatus('error', 'Failed to initialize: ' + e.message);
                console.error(e);
            }
        }

        // Load model
        loadBtn.addEventListener('click', async () => {
            if (!ggufFile || !tokenizerFile) return;
            loadBtn.disabled = true;

            try {
                updateStatus('loading', 'Reading model files...');
                progressContainer.style.display = 'block';
                progressBar.style.width = '10%';

                const [ggufBytes, tokenizerJson] = await Promise.all([
                    ggufFile.arrayBuffer(),
                    tokenizerFile.text(),
                ]);

                progressBar.style.width = '30%';
                updateStatus('loading', 'Loading Q4 model into WebGPU...');

                await client.loadModel(new Uint8Array(ggufBytes), tokenizerJson);

                progressContainer.style.display = 'none';
                updateStatus('ready', 'Model loaded. Select audio to transcribe.');
                updateButtons();
            } catch (e) {
                updateStatus('error', 'Failed to load model: ' + e.message);
                progressContainer.style.display = 'none';
                updateButtons();
                console.error(e);
            }
        });

        // Load model from server (sharded)
        loadServerBtn.addEventListener('click', async () => {
            loadServerBtn.disabled = true;
            loadBtn.disabled = true;

            try {
                progressContainer.style.display = 'block';
                await client.loadFromServer();

                progressContainer.style.display = 'none';
                updateStatus('ready', 'Model loaded from server. Select audio to transcribe.');
                updateButtons();
            } catch (e) {
                updateStatus('error', 'Failed to load model: ' + e.message);
                progressContainer.style.display = 'none';
                updateButtons();
                console.error(e);
            }
        });

        // Load audio file
        document.getElementById('audio-file').addEventListener('change', async (e) => {
            audioFile = e.target.files[0];
            if (!audioFile) return;
            audioInfo.textContent = `File: ${audioFile.name} (${(audioFile.size / 1024).toFixed(1)} KB)`;
            updateButtons();
        });

        // Transcribe file
        transcribeBtn.addEventListener('click', async () => {
            if (!client.isReady() || !audioFile) return;

            transcribeBtn.disabled = true;
            micBtn.disabled = true;
            transcriptionEl.textContent = 'Transcribing...';
            transcriptionEl.classList.add('empty');

            try {
                const text = await client.transcribeFile(audioFile);
                transcriptionEl.textContent = text || '(No speech detected)';
                transcriptionEl.classList.remove('empty');
                updateStatus('ready', 'Done! Select audio to transcribe again.');
            } catch (e) {
                transcriptionEl.textContent = 'Error: ' + (e.message || String(e));
                updateStatus('error', 'Transcription failed');
                console.error(e);
            } finally {
                updateButtons();
            }
        });

        // Microphone recording
        function updateRecTimer() {
            if (!recStartTime) return;
            const elapsed = Math.floor((Date.now() - recStartTime) / 1000);
            const mins = Math.floor(elapsed / 60);
            const secs = elapsed % 60;
            recTimer.textContent = `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        micBtn.addEventListener('click', async () => {
            try {
                await client.startMicrophone();

                micBtn.style.display = 'none';
                stopMicBtn.style.display = '';
                cancelMicBtn.style.display = '';
                micVisualizer.classList.add('active');
                statusDot.classList.add('recording');

                recStartTime = Date.now();
                recTimerInterval = setInterval(updateRecTimer, 1000);
                updateRecTimer();
            } catch (e) {
                updateStatus('error', 'Microphone error: ' + e.message);
                console.error(e);
            }
        });

        stopMicBtn.addEventListener('click', async () => {
            clearInterval(recTimerInterval);
            recTimerInterval = null;

            micBtn.style.display = '';
            stopMicBtn.style.display = 'none';
            cancelMicBtn.style.display = 'none';
            micVisualizer.classList.remove('active');
            statusDot.classList.remove('recording');

            transcriptionEl.textContent = 'Transcribing...';
            transcriptionEl.classList.add('empty');

            try {
                const text = await client.stopAndTranscribe();
                transcriptionEl.textContent = text || '(No speech detected)';
                transcriptionEl.classList.remove('empty');
                updateStatus('ready', 'Done!');
            } catch (e) {
                transcriptionEl.textContent = 'Error: ' + (e.message || String(e));
                updateStatus('error', 'Transcription failed');
                console.error(e);
            } finally {
                updateButtons();
            }
        });

        cancelMicBtn.addEventListener('click', () => {
            client.cancelMicrophone();

            clearInterval(recTimerInterval);
            recTimerInterval = null;

            micBtn.style.display = '';
            stopMicBtn.style.display = 'none';
            cancelMicBtn.style.display = 'none';
            micVisualizer.classList.remove('active');
            statusDot.classList.remove('recording');
            updateStatus('ready', 'Model loaded. Select audio to transcribe.');
        });

        initClient();
    </script>
</body>
</html>
